{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2\n",
    "樊青远 12232509"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this homework, we create a vanilla feed-forward neural network with 2 inputs, 3 outputs, and 1 hidden layer with 2 nodes and bias on the hidden layer and output layer and calculate its forward feed result, categorical cross entropy loss, and gradient of the loss with respect to the weights."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First , we import the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, we define the input data with a given torch random seed, the target data, the weights, and the bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make data\n",
    "torch.manual_seed(4321)\n",
    "X = torch.rand(size=(8, 2))\n",
    "y = torch.randint(low=0, high=3, size=(8,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1255, 0.5377],\n",
      "        [0.6564, 0.0365],\n",
      "        [0.5837, 0.7018],\n",
      "        [0.3068, 0.9500],\n",
      "        [0.4321, 0.2946],\n",
      "        [0.6015, 0.1762],\n",
      "        [0.9945, 0.3177],\n",
      "        [0.9886, 0.3911]])\n",
      "tensor([0, 2, 2, 0, 2, 2, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "# print input data\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, we define the network by using `nn.Module`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct a vanilla feed-forward neural network with 2 inputs, 3 outputs, and 1 hidden layer with 2 nodes and bias on the hidden layer and output layer\n",
    "class Vanilla(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Vanilla, self).__init__()\n",
    "        # define the linear connection layer\n",
    "        self.fc1 = nn.Linear(2, 2, bias=True)\n",
    "        self.fc2 = nn.Linear(2, 3, bias=True)\n",
    "        self.logistic_activate_func = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    \n",
    "    # specify the initial weight\n",
    "    def init_weight(self):\n",
    "        self.fc1.weight.data = torch.tensor([[0.48, -0.51], [-0.43, -0.48]], dtype=torch.float)\n",
    "        self.fc1.bias.data = torch.tensor([0.23, 0.05], dtype=torch.float)\n",
    "        self.fc2.weight.data = torch.tensor([[-0.99, -0.66], [0.36, 0.34], [-0.75, 0.66]], dtype=torch.float)\n",
    "        self.fc2.bias.data = torch.tensor([0.32, -0.44, 0.70], dtype=torch.float)\n",
    "\n",
    "    # connect the components of the network\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.logistic_activate_func(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we calculate the forward feed result, categorical cross entropy loss, and gradient of the loss with respect to the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions of the network:\n",
      "tensor([[0.1867, 0.2663, 0.5470],\n",
      "        [0.1747, 0.2958, 0.5295],\n",
      "        [0.1959, 0.2738, 0.5303],\n",
      "        [0.2022, 0.2590, 0.5388],\n",
      "        [0.1812, 0.2820, 0.5368],\n",
      "        [0.1787, 0.2902, 0.5311],\n",
      "        [0.1863, 0.2966, 0.5171],\n",
      "        [0.1886, 0.2943, 0.5171]], grad_fn=<SoftmaxBackward0>)\n",
      "categorical cross entropy loss:\n",
      "tensor(1.0681, grad_fn=<NllLossBackward0>)\n",
      "gradient of the weights of fc1:\n",
      "tensor([[ 0.0057,  0.0067],\n",
      "        [-0.0017,  0.0058]])\n",
      "gradient of the bias of fc1:\n",
      "tensor([0.0167, 0.0001])\n",
      "gradient of the weights of fc2:\n",
      "tensor([[-0.0059, -0.0053],\n",
      "        [ 0.0323,  0.0252],\n",
      "        [-0.0264, -0.0199]])\n",
      "gradient of the bias of fc2:\n",
      "tensor([-0.0157,  0.0579, -0.0422])\n"
     ]
    }
   ],
   "source": [
    "# use and prediction the model\n",
    "model = Vanilla()\n",
    "model.init_weight()\n",
    "print(\"predictions of the network:\")\n",
    "print(model(X))\n",
    "\n",
    "\n",
    "# loss\n",
    "loss = nn.CrossEntropyLoss()\n",
    "print(\"categorical cross entropy loss:\")\n",
    "print(loss(model(X), y))\n",
    "\n",
    "# calculate the gradient\n",
    "model.zero_grad()\n",
    "loss(model(X), y).backward()\n",
    "\n",
    "# print the gradient\n",
    "print(\"gradient of the weights of fc1:\")\n",
    "print(model.fc1.weight.grad)\n",
    "print(\"gradient of the bias of fc1:\")\n",
    "print(model.fc1.bias.grad)\n",
    "print(\"gradient of the weights of fc2:\")\n",
    "print(model.fc2.weight.grad)\n",
    "print(\"gradient of the bias of fc2:\")\n",
    "print(model.fc2.bias.grad)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eee5015-py39-torchgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a305ffb038d935178ec6e4c02363eb290c7a5404d7bc77dc897f9947beff9331"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
