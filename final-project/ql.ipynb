{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import random\n",
    "import scipy\n",
    "from tqdm.notebook import trange, tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gen graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjacency Matrix:\n",
      "[[ 0.  0.  0.  0.  6.  0.  0.  0.  3.  0.]\n",
      " [ 0.  0.  4.  0. 10.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  3.  9.  0.  0.  0.]\n",
      " [ 9.  0.  0.  0.  0.  0.  0.  0.  9.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  6.  9.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  8.  0.  0.  1.  0.]\n",
      " [ 0.  0.  7.  0.  0.  0.  0.  0.  0.  6.]\n",
      " [ 0.  0.  0.  0.  3.  0.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "def create_weighted_directed_graph_from_adj_matrix(adjacency_matrix):\n",
    "    # Create a directed graph\n",
    "    G = nx.DiGraph()\n",
    "\n",
    "    # Add nodes to the graph\n",
    "    num_nodes = adjacency_matrix.shape[0]\n",
    "    for i in range(num_nodes):\n",
    "        G.add_node(i)\n",
    "\n",
    "    # Add edges from adjacency matrix\n",
    "    for i in range(num_nodes):\n",
    "        for j in range(num_nodes):\n",
    "            weight = adjacency_matrix[i, j]\n",
    "            if weight > 0:  # Add an edge only if weight is greater than 0\n",
    "                G.add_edge(i, j, weight=weight)\n",
    "\n",
    "    return G\n",
    "\n",
    "# Test the function\n",
    "num_nodes = 10\n",
    "\n",
    "# Create a num_nodes by num_nodes matrix filled with zeros\n",
    "adjacency_matrix = np.zeros((num_nodes, num_nodes))\n",
    "\n",
    "# Fill in the adjacency matrix with random edge weights, No self-connections, only 10% of the edges are connected\n",
    "for i in range(num_nodes):\n",
    "    for j in range(num_nodes):\n",
    "        if i != j:  # No self-connections\n",
    "            if random.randint(1, 10) >= 8:\n",
    "                weight = random.randint(1, 10)\n",
    "                adjacency_matrix[i, j] = weight\n",
    "\n",
    "print(\"Adjacency Matrix:\")\n",
    "print(adjacency_matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save('adjacency_matrix_10.npy', adjacency_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7fbe7ce83090>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "adjacency_matrix = np.load('adjacency_matrix_10.npy')\n",
    "G = create_weighted_directed_graph_from_adj_matrix(adjacency_matrix)\n",
    "plt.imshow(adjacency_matrix,cmap='Blues')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neighbors of node 6:\n",
      "[1, 4, 8]\n"
     ]
    }
   ],
   "source": [
    "# print the neighbors of node 6\n",
    "print(\"Neighbors of node 6:\")\n",
    "print(list(G.neighbors(6)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## floyd_warshall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_reward(path):\n",
    "    reward = 0\n",
    "    for i in range(len(path)-1):\n",
    "        reward += adjacency_matrix[path[i],path[i+1]]\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "def floyd_warshall(G):\n",
    "    # Get the number of nodes\n",
    "    n = len(G.nodes)\n",
    "\n",
    "    # Initialize the distance matrix\n",
    "    dist = np.full((n, n), np.inf)\n",
    "\n",
    "    # Initialize the predecessor matrix\n",
    "    pred = np.full((n, n), None)\n",
    "\n",
    "    # Set the diagonal of the distance matrix to 0\n",
    "    np.fill_diagonal(dist, 0)\n",
    "\n",
    "    # Populate the distance and predecessor matrices\n",
    "    for u, v, d in G.edges(data=True):\n",
    "        dist[u, v] = d['weight']\n",
    "        pred[u, v] = u\n",
    "\n",
    "    # Floyd-Warshall\n",
    "    for k in range(n):\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                if dist[i, k] + dist[k, j] < dist[i, j]:\n",
    "                    dist[i, j] = dist[i, k] + dist[k, j]\n",
    "                    pred[i, j] = pred[k, j]\n",
    "\n",
    "    return pred, dist\n",
    "\n",
    "def reconstruct_path(u, v, pred):\n",
    "    path = []\n",
    "    while v is not None:\n",
    "        path.append(v)\n",
    "        v = pred[u, v]\n",
    "    path.reverse()\n",
    "    return path\n",
    "\n",
    "# Assume G is predefined\n",
    "# G = nx.DiGraph()\n",
    "\n",
    "# Run the Floyd-Warshall algorithm\n",
    "predecessor, distance = floyd_warshall(G)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shortest path from node 6 to node 4 is: [6, 4]\n",
      "8.0\n"
     ]
    }
   ],
   "source": [
    "# Find the shortest path from 6 to 4\n",
    "\n",
    "source, target = 6, 4\n",
    "\n",
    "path = reconstruct_path(source, target, predecessor)\n",
    "print(f'The shortest path from node {source} to node {target} is: {path}')\n",
    "print(cal_reward(path))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QLearningAgent:\n",
    "    def __init__(self, graph, num_nodes, alpha=0.5, gamma=0.75, epsilon=0.2):\n",
    "        self.graph = graph\n",
    "        self.num_nodes = num_nodes\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.q_values = np.zeros((num_nodes, num_nodes))  # Q-values initialization\n",
    "\n",
    "    def choose_action(self, state):\n",
    "        neighbors = list(self.graph.neighbors(state))\n",
    "        q_values = [self.q_values[state, action] for action in neighbors]\n",
    "        if np.random.uniform(0, 1) < self.epsilon:\n",
    "            # Choose a random action from the neighbors\n",
    "            action = np.random.choice(neighbors)\n",
    "        else:\n",
    "            # Choose the action with highest Q-value from the neighbors\n",
    "            action = neighbors[np.argmax(q_values)]\n",
    "        return action\n",
    "\n",
    "    def update(self, state, action, reward, next_state):\n",
    "        # Q-learning update\n",
    "        neighbors = list(self.graph.neighbors(next_state))\n",
    "        next_q_values = [self.q_values[next_state, next_action] for next_action in neighbors]\n",
    "        max_next_q_value = max(next_q_values) if neighbors else 0\n",
    "        # apply epsilon-greedy\n",
    "        if np.random.uniform(0, 1) < self.epsilon:\n",
    "            # Choose a random action from the neighbors\n",
    "            next_action = np.random.choice(neighbors)\n",
    "            max_next_q_value = self.q_values[next_state, next_action]\n",
    "        delta = reward + self.gamma * max_next_q_value - self.q_values[state, action]\n",
    "        self.q_values[state, action] += self.alpha * delta\n",
    "            \n",
    "    def learn(self, num_episodes, max_steps_per_episode):\n",
    "        for _ in trange(num_episodes):\n",
    "            state = np.random.randint(0, self.num_nodes)\n",
    "            for step in range(max_steps_per_episode):\n",
    "                action = self.choose_action(state)\n",
    "                reward = -self.graph.edges[state, action]['weight']\n",
    "                next_state = action\n",
    "                self.update(state, action, reward, next_state)\n",
    "                if state == next_state:\n",
    "                    break\n",
    "                state = next_state\n",
    "\n",
    "\n",
    "    def get_optimal_path(self, start_node, end_node):\n",
    "        path = [start_node]\n",
    "        visited = set([start_node])\n",
    "        state = start_node\n",
    "        while state != end_node:\n",
    "            neighbors = list(self.graph.neighbors(state))\n",
    "            # Filter out already visited nodes\n",
    "            neighbors = [node for node in neighbors if node not in visited]\n",
    "            if len(neighbors) == 0:\n",
    "                # return to previous node and select another action\n",
    "                visited.add(state)\n",
    "                path.pop()\n",
    "                state = path[-1]\n",
    "                neighbors = list(self.graph.neighbors(state))\n",
    "                neighbors = [node for node in neighbors if node not in visited]\n",
    "                continue\n",
    "            q_values = [self.q_values[state, action] for action in neighbors]\n",
    "            action = neighbors[np.argmax(q_values)]\n",
    "            visited.add(action)\n",
    "            state = action\n",
    "            path.append(state)\n",
    "        return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2da447a9561643f1a290590f2a4179ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "440fb6a0cc42475eb45f2777d7e9ea8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67c73048273746e097c47a44ea2f12cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(603.0, -965.0, -1568.0, 0.6154336734693877)\n"
     ]
    }
   ],
   "source": [
    "# Initialize the RLAgent\n",
    "agent = QLearningAgent(G, num_nodes)\n",
    "\n",
    "# Learn from the environment\n",
    "agent.learn(num_episodes=50000, max_steps_per_episode=10)\n",
    "\n",
    "print(compare_algorithms(G, len(G.nodes)))\n",
    "\n",
    "# path = agent.get_optimal_path(start_node=6, end_node=4)\n",
    "# print(\"Optimal path from node 6 to node 4: \", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_algorithms(graph, num_nodes):\n",
    "    # Floyd-Warshall\n",
    "    pred, _ = floyd_warshall(graph)\n",
    "    floyd_warshall_rewards = 0\n",
    "    for i in trange(num_nodes):\n",
    "        for j in range(num_nodes):\n",
    "            if i != j:\n",
    "                path = reconstruct_path(i, j, pred)\n",
    "                floyd_warshall_rewards += sum(-graph.edges[path[k], path[k+1]]['weight'] for k in range(len(path)-1))\n",
    "    \n",
    "    # Q-Learning\n",
    "    q_learning_rewards = 0\n",
    "    for i in trange(num_nodes):\n",
    "        for j in range(num_nodes):\n",
    "            if i != j:\n",
    "                path = agent.get_optimal_path(i, j)\n",
    "                q_learning_rewards += sum(-graph.edges[path[k], path[k+1]]['weight'] for k in range(len(path)-1))\n",
    "\n",
    "    return floyd_warshall_rewards - q_learning_rewards, floyd_warshall_rewards, q_learning_rewards, floyd_warshall_rewards / q_learning_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal path from node 6 to node 4:  [6, 8, 5, 4]\n",
      "Total reward:  -22.0\n"
     ]
    }
   ],
   "source": [
    "path = agent.get_optimal_path(start_node=6, end_node=4)\n",
    "print(\"Optimal path from node 6 to node 4: \", path)\n",
    "# calculate the total reward\n",
    "total_reward = 0\n",
    "for i in range(len(path) - 1):\n",
    "    total_reward += -G.edges[path[i], path[i + 1]]['weight']\n",
    "print(\"Total reward: \", total_reward)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eee5015-py311-torchgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
